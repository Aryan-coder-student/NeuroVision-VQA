params:
  batch_size: 8
  num_epochs: 50
  learning_rate: 5e-5
  weight_decay : 1e-4
  gradient_accumulation_steps: 4
  patience : 10